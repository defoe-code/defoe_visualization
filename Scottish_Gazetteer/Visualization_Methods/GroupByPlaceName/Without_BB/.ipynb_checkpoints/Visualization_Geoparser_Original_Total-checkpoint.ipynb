{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Original Geoparser - Total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have used the [Edinburgh geoparser](https://programminghistorian.org/en/lessons/geoparsing-text-with-edinburgh#patch-fix) with the original language model for finding the Name Entities for all Scottish Gazetteers, and select just the ones regarding with places. Later, once we have the locations entities, we have used the georesolver to resolve these locations.\n",
    "                       \n",
    "The query for running that we have used is the following: \n",
    "\n",
    "`sspark-submit --py-files defoe.zip defoe/run_queries.py nls_gaz.txt  nls -l query_distributed_topics.txt -n 16 `\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from IPython.core.display import display, HTML\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_query_results(filename):\n",
    "    with open('../../../results_Gazetteer/results_without_bb/'+filename, 'r') as f:\n",
    "        query_results = yaml.load(f)\n",
    "    return query_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geresolution_dataframe(result):\n",
    "    dfs=[]\n",
    "    data=[]\n",
    "    c_locs=[]    \n",
    "    for i in result.keys():\n",
    "        print(\"year %s\" %i)\n",
    "        t_ind = 0\n",
    "        e_ind = 0\n",
    "        year = i\n",
    "        for k in result[i]:\n",
    "            locs= k[\"georesolution_page\"]\n",
    "            page = k[\"text_unit id\"]\n",
    "            if locs != {}:\n",
    "                data=[]\n",
    "                l_ind = 0\n",
    "                for t in locs:\n",
    "                    if type(locs[t]) == type([]) :\n",
    "                        c_locs=locs[t].copy()\n",
    "                        c_locs.append(t.split(\"-\")[0])\n",
    "                        c_locs.append(page)\n",
    "                        c_locs.append(year)\n",
    "                        data.append(c_locs)\n",
    "                        l_ind = l_ind + 1   \n",
    "                e_ind = t_ind + l_ind \n",
    "                if data:\n",
    "                    df_page = pd.DataFrame(data, columns = ['Latitude', 'Longitude', 'Place', 'Page', 'Year'], \n",
    "                                      index=list(range(t_ind, e_ind)))\n",
    "                    dfs.append(df_page)\n",
    "                    t_ind=e_ind\n",
    "    df_total = pd.concat(dfs)\n",
    "    return df_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_place(df, lat, long):\n",
    "    df_new=df.loc[(df['Latitude'] == lat) & (df['Longitude'] == long)]['Place']\n",
    "    return df_new.count(), df_new.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_freq_places(df_total, df_max_geolocations, filter_list):\n",
    "    place_label=[]\n",
    "    place_freq = []\n",
    "    i_limit = 15\n",
    "    i =0\n",
    "    k =0 \n",
    "    while k < i_limit:\n",
    "        place_count, place_name = get_place(df_total, df_max_geolocations.iloc[i]['Latitude'], df_max_geolocations.iloc[i]['Longitude'])\n",
    "        if place_name not in filter_list:\n",
    "            print(i, place_count,place_name)\n",
    "            if place_name not in place_label:\n",
    "                k = k + 1\n",
    "            place_label.append(place_name)\n",
    "            place_freq.append(place_count)\n",
    "         \n",
    "        i = i + 1\n",
    "    return place_label, place_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bar_places(place_label, place_freq, plot_type='resolved'):\n",
    "    # this is for plotting purpose\n",
    "    index = np.arange(len(place_label))\n",
    "    plt.xlabel('Places', fontsize=15)\n",
    "    plt.ylabel('Frequency of Places', fontsize=15)\n",
    "    plt.xticks(index, place_label, rotation=80, fontsize=15)\n",
    "    plt.tick_params(axis='both', which='minor', labelsize=15)\n",
    "\n",
    "    if plot_type == \"resolved\":\n",
    "        plt.bar(index, place_freq, color='orange')\n",
    "        plt.title('15 Places most mentioned using \\n' +  ' the Original Geoparser across all Scottish Gazetteers')\n",
    "    else:\n",
    "        plt.bar(index, place_freq, color='coral')\n",
    "        plt.title('15 Places most mentioned but not resolved using \\n' +  'the Original Geoparser across all Scottish Gazetteers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information about the defoe geoparser query\n",
    "\n",
    "This query does the following tasks:\n",
    "\n",
    "- Ingests all the pages from each directory listed in nls_gaz.txt, which each corresponds to a book of the \"Scottish Gazzeters\"\n",
    "- Cleans the text applied two fixes: Long-s and hyphen words\n",
    "- Identifies *entities*.\n",
    "- From the previous entities, just selects the one about *location* and creates an xml (in memory) per page with these \"location\" entities. \n",
    "- Applies the georesolve of the Edinburgh geoparser to each xml and gets lat and long. **Important: Everything is in memory, we do not create XML files in those steps**\n",
    "- Group the results by year, and also gets some informative metadata\n",
    "\n",
    "\n",
    "As a result we get a file per book with an entry per page with the following information:\n",
    "\n",
    "    * edition: Edition of the gazetteer\n",
    "    * georesolution_page: Page's geolocations after applying the georesolver\n",
    "    * page_filename: Page's filename (page's relative path)\n",
    "    * text_unit id: The number of this page (e.g. Page 1)\n",
    "    * lang_model : The language model applied (original_geoparser)\n",
    "    * year: Publication year \n",
    "\n",
    "`Example:\n",
    "     \n",
    "    - edition: '1828'\n",
    "      georesolution_page:\n",
    "       Aberdeen-rb19:\n",
    "        - '57.1333333'\n",
    "        - '-2.1'\n",
    "       Edinburgh-rb7:\n",
    "        - '55.9497284685701'\n",
    "        - '-3.19333076477051'\n",
    "    \n",
    "      lang_model: geoparser_original\n",
    "      page_filename: alto/97351031.34.xml\n",
    "      text_unit id: Page27\n",
    "      title: Descriptive account of the principal towns in Scotland to accompany Wood's town atlas`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the file and creating the first dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=read_query_results('geoparser_original_total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total= geresolution_dataframe(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generic Explorations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important: Number of Places that has been identified!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total[[\"Place\"]].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important: Going to remove City of | Contry of | County of  in the strings of Places**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total['Place'] = df_total['Place'].str.replace(r'City of ', '')\n",
    "df_total['Place'] = df_total['Place'].str.replace(r'city of ', '')\n",
    "df_total['Place'] = df_total['Place'].str.replace(r'Country of ', '')\n",
    "df_total['Place'] = df_total['Place'].str.replace(r'country of ', '')\n",
    "df_total['Place'] = df_total['Place'].str.replace(r'County of ', '')\n",
    "df_total['Place'] = df_total['Place'].str.replace(r'county of ', '')\n",
    "df_total['Place'] = df_total['Place'].str.replace(r'the ', '')\n",
    "df_total['Place'] = df_total['Place'].str.replace(r'The ', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important: Number of Places that has been identified but not resolved!**\n",
    "\n",
    "Creating a dataframe, df_not_resolved for futher exploration at the end of the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_not_resolved=df_total.loc[df_total['Latitude'] == '']\n",
    "df_not_resolved.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important: Number of Places that has been identified AND  resolved!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.loc[df_total['Latitude'] != ''].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the places resolved (with latitude and longitude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important: New dataframe- df_resolved- with just the rows has been resolved!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resolved = df_total[df_total['Latitude'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resolved.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Places names - forcing all to lower case, and later capitalize them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df_resolved.copy()\n",
    "df2['Place']=df_resolved['Place'].apply(str.lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_capitalized= df2.copy()\n",
    "df_capitalized['Place']=df2['Place'].apply(str.capitalize)\n",
    "#Displaying the first 15 rows\n",
    "df_capitalized.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_max_geolocations= df_capitalized[['Latitude','Longitude', 'Place']].groupby(['Place'])['Place'] \\\n",
    "                             .count() \\\n",
    "                             .reset_index(name='count') \\\n",
    "                             .sort_values(['count'], ascending=False)  \n",
    "print(df_max_geolocations.count())\n",
    "#displaying just the first 15 rows\n",
    "df_max_geolocations.head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the 15 places (and their frequencies) most mentioned\n",
    "place_label= df_max_geolocations['Place'].tolist()[0:15]\n",
    "place_freq= df_max_geolocations['count'].tolist()[0:15]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.dpi']=300\n",
    "plot_bar_places(place_label, place_freq, plot_type='resolved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the locations not resolved\n",
    "\n",
    "Places names - forcing all to lower case, and later capitalize them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df_not_resolved.copy()\n",
    "df4['Place']=df_not_resolved['Place'].apply(str.lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_not_res_cap= df4.copy()\n",
    "df_not_res_cap['Place']=df4['Place'].apply(str.capitalize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_not_resolved_max = df_not_res_cap[['Place']].groupby(['Place'])['Place'] \\\n",
    "                             .count() \\\n",
    "                             .reset_index(name='count') \\\n",
    "                             .sort_values(['count'], ascending=False)   \n",
    "\n",
    "print(df_not_resolved_max.count())\n",
    "#displapying the first 15 rows\n",
    "df_not_resolved_max.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the 15 places (and their frequencies) most mentioned\n",
    "place_label_not_resolved= df_not_resolved_max['Place'].tolist()[0:15]\n",
    "place_freq_not_resolved= df_not_resolved_max['count'].tolist()[0:15]\n",
    "plot_bar_places(place_label_not_resolved, place_freq_not_resolved, plot_type='not_resolved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
